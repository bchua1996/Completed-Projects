---
title: "Spotify Analysis"
author: "Katie Herlihy, Jack Cronin, David Barnes, Jamar Manning and Brendan Chua"
date: "9/29/2020"
output:
  revealjs::revealjs_presentation:
    theme: night
    highlight: zenburn
    center: true
    transition: fade
    slide_level: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(ggplot2)
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
SpotifyFeatures <- read_csv("~/Downloads/SpotifyFeatures.csv")
```

## Introduction

We are executives of a record label, and are hoping to run some analytics to help us gain some insight into what makes popular music popular, so that we can better identify key features that make up a successful song and use that information in the future. 

## Our Data

Our data was retrieved from Kaggle.com, and it is best described as the top tracks from 1920-2020, with approximately 10,000 songs selected per genre

```{r}
head(SpotifyFeatures)
```

## Additional variables assigned to each song: 
(as defined by <a href = "https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/">Spotify</a>)

<p class="fragment fade-in-then-semi-out">danceability,
loudness,
speechiness,
popularity, 
mode, 
key,
acousticness,
liveness,
instrumentalness,
valence </p> 


## Data Errors

Upon further inspection, we decided to clean up our data so any models we run
will have accurate implications. This meant that we excluded the *Comedy*
genre, because comedy specials are not the concern of our label executives
and it may skew our findings. We are also converting the duration from ms to seconds.
We also detected a spelling error that resulted in duplicate columns, so corrected that
as well.

```{r}
SpotifyFeatures <- SpotifyFeatures %>%
  filter(genre !="Comedy") %>%
  filter(genre != "Children's Music")

SpotifyFeatures <- SpotifyFeatures %>%
  mutate(duration_ms= duration_ms/1000) %>%
  rename(duration_s = duration_ms)
```

## Problem #1:*Music Festival*

Our label is sponsoring a music festival and we are trying to decide which genre to invite to perform. As an executive producer, we believe that <span style="color:green">*danceability*</span> is a huge factor in attendee satisfaction.

> *Danceability* describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.

##
From this graph we see that the distribution of danceability between
Electronic and Dance music is very similar, with a little bit of a 
wider distribution within the Electronic genre. 

```{r, echo = FALSE, message = FALSE, warning = FALSE}
SpotifyFeatures %>%
  filter(genre=="Electronic" |
           genre== "Dance") %>%
  
  ggplot(DanceElectronic, mapping = aes(x=danceability)) +
  geom_density(aes(fill=genre)) +
  facet_wrap(~ genre)
```

##
Next, we wanted to see how the average danceability between these two
genres compared.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
DanceGenre <- SpotifyFeatures %>%
  filter(genre == "Dance")

DanceDanceabilityMean <- mean(DanceGenre$danceability)

ElectronicGenre <- SpotifyFeatures %>%
  filter(genre == "Electronic")

ElectronicGenreMean <- mean(ElectronicGenre$danceability)

```
We see that the average danceability is very similar between these two 
categories- *but are they significantly different?*


```{r}
DanceDanceabilityMean
ElectronicGenreMean
```

## Testing Approach {data-transition="zoom"}

We are going to run a two-sided hypothesis test. We are wondering <span style="color:green">*if the danceability between Dance and Electronic music is significantly different*</span>,  so we can determine which genre will be a better fit for our event.



$$ d = difference$$
$$h_0: d = 0$$
$$h_1: d \neq 0$$

## Running our T-Test

```{r, echo = FALSE, message = FALSE, warning = FALSE}
DanceabilityDifferences <- t.test(DanceGenre$danceability, ElectronicGenre$danceability, mu=0, alternative = "two.sided")
DanceabilityDifferences
```

## Test Results
Our test shows that the danceability between Dance and Electronic music are
significantly different, by looking at both the confidence interval and the
p-value. While we were not expecting the danceability of the two categories to be significantly different because the averages were so similar, we see now that the difference of means is indeed significant and therefore we will choose to 
feature Dance music in our festival.

## Problem #2: *Introducing more live song versions*

Many of our artists have expressed interest in releasing live versions of their most popular songs, and we are wondering if having a higher <span style="color:green">liveness</span> leads to above average popularity. If this is true, we will consider more live versions of songs in order to increase total revenues.

> *Liveness* detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live. 

##
> 'Popularity' is determined by the popularity of the song lately (default country = US). Ranked on a scale 1-100.


##
We first ran a density plot for liveness, and found it very skewed to the right.
Because of this, we decided to use the median as the defining point for 'high' or 'low' liveness as opposed to the mean.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
  ggplot(SpotifyFeatures, mapping = aes(x=liveness)) +
  geom_density()

```
## 

## We used these parameters to create a "HighLiveness" subset from our main data:
```{r}
HighLiveness <- SpotifyFeatures %>%
  filter(liveness>0.128)
HighLiveness
```

## Testing Approach {data-transition="zoom"}

$$h_0: Average\,\,Popularity\,\,of \,\, High\,\,Liveness<= 41.3$$
$$h_1: Average\,\,Popularity\,\,of \,\, High\,\,Liveness > 41.3$$

## Running our T-Test
```{r, echo = FALSE, message = FALSE, warning = FALSE}
LivenessPopularity <- t.test(HighLiveness$popularity, mu=43.13, alternative = "greater")
LivenessPopularity  
```

## Test Results
After running this test, we fail to reject the null hypothesis; the average 
popularity for songs with 'high liveness' is not significantly above average.


 
## Problem #3: *Factors of Popularity*
As a music label, we see that times are changing and it’s important to stay on top of current trends. We are very interested in identifying the factors that influence the popularity of songs. We believe that popularity is the most valuable KPI, and it is the most directly related to revenue. 


##
We first ran a <span style="color:gold">single variable regression analysis</span> of genre on popularity.

> We expected the genre in which songs lie to be pretty closely correlated with whether a song was popular or not, and our findings support this


```{r, echo = FALSE, message = FALSE, warning = FALSE}
LMgenre <- lm(popularity ~ genre, SpotifyFeatures)
summary(LMgenre)
```

##
As people who want to really gain a deeper understanding of the music, we want to look into more than just genre as a predictor of popularity; we want to know what factors of the music explain the other 30% of variance in popularity. 

##
We decide to run a multivariable regression model, using <span style="color:gold">acousticness, loudness and danceability</span>  as independent variables against <span style="color:gold">popularity</span>.

> Acousticness is the relative metric of the track being acoustic (0-1); 
> Loudness is the relative loudness of the track in the typical range [-60, 0] in decibel (dB)

##
We chose these factors because they had the highest R^2 for the remaining variables when they were all run individually against popularity:

```{r, echo = FALSE, message = FALSE, warning = FALSE}
LMAll <- lm(popularity ~ acousticness + danceability + loudness, SpotifyFeatures)
summary(LMAll)
```

##
We get some good insights from running this regression analysis. These 3 factors explain approximately 17% of the data- when we think about how much variance was left over from the genre linear regression, we are pretty happy with these insights. 

> It seems that generally a unit increase of acousticness results in -6 units of popularity, and a unit increase of danceability results in a 17 unit increase in popularity. A less helpful finding was that a unit increase of loudness leads to only a .52 unit increase of popularity.

## How we'll use these results:
We know that while genre is probably the best indicator of popularity, we now know which variables we can run when asked to choose between multiple songs that are within a single genre. 

>For example, if the ultimate goal for a record launch is popularity, we can use a regression analysis similar to this to determine which songs should be selected as the album’s singles.

## Concluding Thoughts 
While we believe that analytics can be a very strong when trying to reach definite conclusions about a particular dataset, we want to acknowledge that many other factors come into play when considering music.

##
Music is a very subjective field, and we would be cautious of
placing too much confidence in the numbers. Trends can very quickly change, and no analysis can determine if a song is 'good' or 'bad'. For example, earlier we ran a regression model identifying loudness as one of the main predictors in popularity.


##
Let's take a look at how loudness plays into popularity for two different artists, both very successful in their respective genres:

```{r, echo = FALSE, message = FALSE, warning = FALSE}

par(mfrow=c(1,2))
ArianaGrande <- SpotifyFeatures %>%
  filter(artist_name == "Ariana Grande") 
The1975 <- SpotifyFeatures %>%
  filter(artist_name == "The 1975")


scatter.smooth(x=ArianaGrande$loudness, y=ArianaGrande$popularity, main="loudness~ popularity")
scatter.smooth(x=The1975$loudness, y=The1975$popularity, main="loudness~ popularity")

```

## 
While we made conclusions about loudness within the dataset as a whole, these models may be most useful when run within a single genre or for a single artist. Each artist within a genre may have different variables that deem them 'successful', however our analysis offers a very generic overview of Spotify's top tracks within the last 100 years.

## Additional Data 
 We would have liked to see the date of each song's release, so that we could better observe industry trends within genre throughout time.

We also would have liked some data regarding song engagement, specifically number of downloads or radio streams. This would give us more insight as to what contributes to the definition of what is classified as 'popular'.

## 
 
